{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l_helper\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#人造数据集\n",
    "def synthetic_data(w,b,num_examples):\n",
    "    X=d2l_helper.normal(0,1,(num_examples,len(w)))\n",
    "    y=d2l_helper.matmul(X,w)+b\n",
    "    y+=d2l_helper.normal(0,0.01,y.shape)\n",
    "    return X,y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2555063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size,features,labels):\n",
    "    num_examples=len(features)\n",
    "    indices=list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "        batch_indices=d2l_helper.tensor(indices[i:min(i+batch_size,num_examples)])\n",
    "    yield features[batch_indices],labels[batch_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3ec60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2038, -0.2301],\n",
      "        [ 0.6003,  0.8560],\n",
      "        [ 0.7269,  0.2439],\n",
      "        [-0.9086, -0.4832],\n",
      "        [-0.0400, -0.7127],\n",
      "        [ 0.7884,  0.0021],\n",
      "        [ 0.3913,  0.5942],\n",
      "        [-0.6643,  1.4171],\n",
      "        [ 0.0574, -0.1358],\n",
      "        [ 1.7468, -2.0483]]) \n",
      " tensor([[-1.3495],\n",
      "        [ 4.6641],\n",
      "        [ 2.7439],\n",
      "        [-4.0493],\n",
      "        [-2.7416],\n",
      "        [ 1.9783],\n",
      "        [ 3.1867],\n",
      "        [ 3.6053],\n",
      "        [-0.3524],\n",
      "        [-3.1930]])\n"
     ]
    }
   ],
   "source": [
    "#have a little try of data_iter output,生成第一轮i=0的batch就break\n",
    "true_batch_size=10\n",
    "#注意这个地方的true_w必须要是张量类型\n",
    "true_w=d2l_helper.tensor([2.5,3.7])\n",
    "true_b=0.01\n",
    "features_1,labels_1=synthetic_data(true_w,true_b,1000)\n",
    "for X,y in data_iter(true_batch_size,features_1,labels_1):\n",
    "    print(X,'\\n',y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "def linreg(X,w,b):\n",
    "    return d2l_helper.matmul(X,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe0ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat,y):\n",
    "    y=y.reshape(-1,1)\n",
    "    return (y_hat-y)**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420bce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimization method\n",
    "def sgd(params,lr,batch_size):\n",
    "#临时禁用梯度计算，torch.no_grad()\n",
    "    with d2l_helper.no_grad():\n",
    "        for param in params:\n",
    "#自动微分机制，w定义的时候用了requires_grad=True\n",
    "            param-=lr*param.grad/batch_size\n",
    "            param.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d4251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin training\n",
    "lr=0.03\n",
    "num_epochs=3\n",
    "net=linreg\n",
    "loss=squared_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=d2l_helper.normal(0,1,(2,1),requires_grad=True)\n",
    "b=d2l_helper.zeros(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5dec227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1000, 2])\n",
      "y shape: torch.Size([1000, 1])\n",
      "y_hat shape: torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", features_1.shape)\n",
    "print(\"y shape:\", labels_1.shape)\n",
    "print(\"y_hat shape:\", net(features_1, w, b).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b4c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss4.391857\n",
      "epoch2,loss3.960859\n",
      "epoch3,loss3.647053\n"
     ]
    }
   ],
   "source": [
    "num_epochs=3\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(true_batch_size,features_1,labels_1):\n",
    "    #l是当前批次损失，但是train_l是全量训练集损失\n",
    "        l=loss(net(X,w,b),y)\n",
    "        l.sum().backward(retain_graph=True)\n",
    "        sgd([w,b],lr,true_batch_size)\n",
    "    with d2l_helper.no_grad():\n",
    "        train_l=loss(net(features_1,w,b),labels_1)\n",
    "        print(f'epoch{epoch+1},loss{float(train_l.mean()):f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
